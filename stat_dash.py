#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import dash
import dash_bootstrap_components as dbc
from dash import dcc, html, dash_table, Input, Output, State, MATCH, ALL, DiskcacheManager
import pandas as pd
import plotly.express as px
import re
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import os
import time
import diskcache
import datetime
import numpy as np
import sys
import dash
import plotly
import requests
import base64
from scipy.stats import ttest_ind
from statsmodels.stats.multitest import multipletests
import argparse
import hashlib
from dash.dependencies import Input, Output, State, ALL

# --- Ïª¨Îü¨ ÌåîÎ†àÌä∏ Ï†ïÏùò ---
# [ÏÑ§Î™Ö] ÏùºÍ¥ÄÎêú Î∏åÎûúÎìú Ïª¨Îü¨ÏôÄ ÏãúÍ∞ÅÏ†Å Í≥ÑÏ∏µÍµ¨Ï°∞Î•º ÏúÑÌïú Ïª¨Îü¨ ÌåîÎ†àÌä∏
COLORS = {
    'primary': '#2c3e50',      # ÏßÑÌïú ÎÑ§Ïù¥ÎπÑ (Î©îÏù∏ Î∏åÎûúÎìú Ïª¨Îü¨)
    'secondary': '#3498db',    # Î∞ùÏùÄ Î∏îÎ£® (Î≥¥Ï°∞ Ïª¨Îü¨)
    'accent': '#e74c3c',       # Îπ®Í∞ï (Í∞ïÏ°∞/Í≤ΩÍ≥†)
    'success': '#27ae60',      # Ï¥àÎ°ù (ÏÑ±Í≥µ/ÏôÑÎ£å)
    'warning': '#f39c12',      # Ï£ºÌô© (Í≤ΩÍ≥†)
    'info': '#17a2b8',         # Ï≤≠Î°ù (Ï†ïÎ≥¥)
    'light': '#ecf0f1',        # Ïó∞Ìïú ÌöåÏÉâ (Î∞∞Í≤Ω)
    'dark': '#2c3e50',         # ÏßÑÌïú ÌöåÏÉâ (ÌÖçÏä§Ìä∏)
    'white': '#ffffff',        # Ìù∞ÏÉâ
    'gray': '#95a5a6'          # Ï§ëÍ∞Ñ ÌöåÏÉâ
}

# Plotly Ï∞®Ìä∏Ïö© Ïª¨Îü¨ ÌåîÎ†àÌä∏
PLOTLY_COLORS = ['#2c3e50', '#3498db', '#e74c3c', '#27ae60', '#f39c12', '#17a2b8', '#9b59b6', '#34495e']

# --- study_out_dir ÏßÄÏ†ï (Ïã§Ìñâ Ïù∏Ïûê/ÌôòÍ≤ΩÎ≥ÄÏàò Ïö∞ÏÑ†) ---
def get_study_out_dir():
    parser = argparse.ArgumentParser()
    parser.add_argument('--study_out_dir', type=str, default=None)
    args, _ = parser.parse_known_args()
    study_out_dir = args.study_out_dir or os.environ.get('STUDY_OUT_DIR') or str(Path.cwd())
    return study_out_dir

STUDY_OUT_DIR = get_study_out_dir()

# --- Î∞±Í∑∏ÎùºÏö¥Îìú ÏΩúÎ∞± Îß§ÎãàÏ†Ä ÏÑ§Ï†ï ---
# [ÏÑ§Î™Ö] Î∂ÑÏÑù ÏûëÏóÖÏùò Ï∫êÏãú Î∞è ÎπÑÎèôÍ∏∞ Ï≤òÎ¶¨Î•º ÏúÑÌïú diskcacheÏôÄ DashÏùò Î∞±Í∑∏ÎùºÏö¥Îìú ÏΩúÎ∞± Îß§ÎãàÏ†ÄÎ•º ÏÑ§Ï†ïÌï©ÎãàÎã§.
# Ï∫êÏãú Í≤ΩÎ°úÎ•º /tmp ÏïÑÎûòÎ°ú ÏßÄÏ†ïÌïòÏó¨ Í∂åÌïú Î¨∏Ï†ú Î∞©ÏßÄ
cache_directory = "/tmp/my_dash_analyzer_cache"
os.makedirs(cache_directory, exist_ok=True)
cache = diskcache.Cache(cache_directory)
background_callback_manager = DiskcacheManager(cache)

# --- Î∂ÑÏÑù Î°úÏßÅ ---
# [ÏÑ§Î™Ö] Í≤∞Í≥º ÌååÏùº(.out)ÏóêÏÑú stat Í∞íÏùÑ Ï∂îÏ∂úÌïòÍ≥†, DataFrameÏúºÎ°ú ÏßëÍ≥ÑÌïòÎäî Ï£ºÏöî Î∂ÑÏÑù Ìï®ÏàòÎì§ÏûÖÎãàÎã§.
def load_stats_to_find(stats_file='stats.txt'):
    stats_path = Path(stats_file)
    if not stats_path.is_file():
        # Í∏∞Î≥∏Í∞í Ï†úÍ≥µ (ÌååÏùº ÏóÜÏùÑ Îïå)
        return ['ipc', 'power', 'L2_cache_miss_rate', 'total_power']
    with open(stats_path, 'r', encoding='utf-8') as f:
        stats = [line.strip() for line in f if line.strip() and not line.strip().startswith('#')]
    return stats

STATS_TO_FIND = load_stats_to_find('stats.txt')
KEY_VALUE_PATTERN = re.compile(r"^\s*(\S+)\s*=\s*([-+]?(?:\d*\.\d+|\d+)(?:[eE][-+]?\d+)?|[Nn][Aa][Nn])")

def process_single_report(report_path: Path, stats_to_find: list, group_name: str):
    # group, subgroup, run Ï∂îÏ∂ú
    run_name = report_path.parent.name
    subgroup_name = report_path.parent.parent.name
    # group_nameÏùÄ analyze_directoryÏóêÏÑú Ï†ÑÎã¨Î∞õÏùå
    values_dict = {stat: [] for stat in stats_to_find}
    matched_keys_dict = {stat: set() for stat in stats_to_find}
    search_started = False
    try:
        with open(report_path, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                if not search_started:
                    if "Running Complete" in line:
                        search_started = True
                    continue
                match = KEY_VALUE_PATTERN.search(line)
                if match:
                    found_key, value_str = match.groups()
                    for stat in stats_to_find:
                        if stat in found_key:
                            value = 0.0 if value_str.lower() == 'nan' else float(value_str)
                            values_dict[stat].append(value)
                            matched_keys_dict[stat].add(found_key)
    except IOError:
        return None
    averages = {stat: sum(v) / len(v) for stat, v in values_dict.items() if v}
    # matched_keys_dict: only keep those with values
    matched_keys_dict = {stat: list(keys) for stat, keys in matched_keys_dict.items() if values_dict[stat]}
    result = (group_name, subgroup_name, run_name, averages, matched_keys_dict) if averages else None
    return result


from concurrent.futures import ProcessPoolExecutor, as_completed  # Î≥ÄÍ≤Ω: Î©ÄÌã∞ÌîÑÎ°úÏÑ∏Ïã± ÏÇ¨Ïö©

def analyze_directory(root_path: Path, stats_to_find: list):
    # [ÏÑ§Î™Ö] ÏßÄÏ†ïÌïú ÎîîÎ†âÌÜ†Î¶¨ ÎÇ¥ Î™®Îì† Í≤∞Í≥º ÌååÏùºÏùÑ Î≥ëÎ†¨Î°ú Î∂ÑÏÑùÌïòÏó¨ DataFrameÏúºÎ°ú ÏßëÍ≥ÑÌï©ÎãàÎã§.
    report_files = list(root_path.rglob("*.out"))
    if not report_files:
        return None, {}
    group_name = root_path.name  # baseline_dir ÎòêÎäî target_dirsÏùò Ìè¥ÎçîÎ™Ö
    results = []
    all_matched_keys = {stat: set() for stat in stats_to_find}
    # Ï∫êÏãú Ï†ÅÏö©: ÌååÏùºÎ≥ÑÎ°ú Ï∫êÏãú ÌôïÏù∏ Î∞è Ï†ÄÏû•
    stats_hash = hashlib.md5(','.join(stats_to_find).encode()).hexdigest()
    uncached_files = []
    cache_results = {}
    for report_path in report_files:
        cache_key = (str(report_path.resolve()), os.path.getmtime(report_path), stats_hash)
        cached = cache.get(cache_key, default=None)
        if cached is not None:
            # Ï∫êÏãúÍ∞Ä 4Í∞ú tupleÏù¥Î©¥, matched_keys_dictÎ•º Îπà dictÎ°ú Î≥¥Ï†ï
            if isinstance(cached, tuple) and len(cached) == 4:
                group, subgroup, run, averages = cached
                matched_keys_dict = {}
                cache_results[report_path] = (group, subgroup, run, averages, matched_keys_dict)
            else:
                cache_results[report_path] = cached
        else:
            uncached_files.append(report_path)
    # uncached_filesÎßå Î©ÄÌã∞ÌîÑÎ°úÏÑ∏Ïã±ÏúºÎ°ú Ï≤òÎ¶¨
    if uncached_files:
        with ProcessPoolExecutor(max_workers=8) as executor:
            futures = [executor.submit(process_single_report, file, stats_to_find, group_name) for file in uncached_files]
            for idx, future in enumerate(as_completed(futures)):
                result = future.result()
                if result:
                    # Ï∫êÏãúÏóê Ï†ÄÏû•
                    report_path = uncached_files[idx]
                    cache_key = (str(report_path.resolve()), os.path.getmtime(report_path), stats_hash)
                    cache.set(cache_key, result)
                    cache_results[report_path] = result
    # Í≤∞Í≥º Ìï©ÏπòÍ∏∞
    for report_path in report_files:
        result = cache_results.get(report_path)
        if result:
            group, subgroup, run, stats, matched_keys_dict = result
            results.append((group, subgroup, run, stats))
            for stat, keys in matched_keys_dict.items():
                all_matched_keys[stat].update(keys)
    if not results:
        return None, {stat: list(keys) for stat, keys in all_matched_keys.items()}
    # group, subgroup, run, statÎ≥ÑÎ°ú DataFrame ÏÉùÏÑ±
    records = []
    for group, subgroup, run, stats in results:
        for stat, value in stats.items():
            records.append({
                'Group': group,
                'Subgroup': subgroup,
                'Run': run,
                'Stat': stat,
                'Value': value
            })
    df = pd.DataFrame(records)
    if df.empty:
        return None, {stat: list(keys) for stat, keys in all_matched_keys.items()}
    # Subgroup prefix(Ïïû 5Í∏ÄÏûê)Î°ú Î≥ëÌï©
    df['SubgroupPrefix'] = df['Subgroup'].str[:5]
    # RunÏùÄ Í∑∏ÎåÄÎ°ú ÎëêÍ≥†, Group, SubgroupPrefix, Run, StatÎ≥ÑÎ°ú ÌèâÍ∑†
    df_agg = df.groupby(['Group', 'SubgroupPrefix', 'Run', 'Stat'], as_index=False)['Value'].mean()
    df_agg = df_agg.rename(columns={'SubgroupPrefix': 'Subgroup'})
    return df_agg, {stat: list(keys) for stat, keys in all_matched_keys.items()}


def find_subdirectories(base_path: Path, depth: int) -> list:
    # [ÏÑ§Î™Ö] Í∏∞Ï§Ä Í≤ΩÎ°úÏóêÏÑú ÏßÄÏ†ïÌïú depthÍπåÏßÄ ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨Î•º ÌÉêÏÉâÌï¥ Î™©Î°ùÏùÑ Î∞òÌôòÌï©ÎãàÎã§.
    dirs = set()
    if not base_path.is_dir(): return []
    with os.scandir(base_path) as it:
        for entry in it:
            if entry.is_dir():
                dirs.add(str(Path(entry.path).resolve()))
                if depth > 1:
                    try:
                        with os.scandir(entry.path) as sub_it:
                            for sub_entry in sub_it:
                                if sub_entry.is_dir():
                                    dirs.add(str(Path(sub_entry.path).resolve()))
                    except PermissionError:
                        continue
    return sorted(list(dirs))

# --- Dash Ïï± Íµ¨ÏÑ± ---
# [ÏÑ§Î™Ö] Dash Ïï± Í∞ùÏ≤¥, ÏÑúÎ≤Ñ, ÌÉÄÏù¥ÌãÄ, Ïô∏Î∂Ä Ïä§ÌÉÄÏùº, Î∞±Í∑∏ÎùºÏö¥Îìú ÏΩúÎ∞± Îß§ÎãàÏ†Ä Îì±ÏùÑ ÏÑ§Ï†ïÌï©ÎãàÎã§.
app = dash.Dash(__name__, external_stylesheets=[dbc.themes.FLATLY], background_callback_manager=background_callback_manager)
server = app.server
app.title = "Monaco Simulation Analyzer"
discovered_dirs = find_subdirectories(Path(STUDY_OUT_DIR), depth=5)
dir_options = [{'label': os.path.basename(p), 'value': p} for p in discovered_dirs]

# 1. ÏÇ¨Ïù¥ÎìúÎ∞î controlsÏóê stat Î™©Î°ù Ìé∏Ïßë UI Ï∂îÍ∞Ä
controls = dbc.Card([
    dbc.CardHeader([
        html.H4("üìä Analysis Configuration", className="card-title mb-0", 
                style={"color": COLORS['primary'], "fontWeight": "600"})
    ], style={"backgroundColor": COLORS['light'], "borderBottom": f"3px solid {COLORS['secondary']}"}),
    dbc.CardBody([
        # study_out_dir ÏûÖÎ†• Î∞è Search Î≤ÑÌäº
        html.Div([
            html.H5("Study Output Directory", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "10px"}),
            dcc.Input(id='study-out-dir-input', type='text', value=STUDY_OUT_DIR, style={"width": "80%", "marginRight": "8px"}),
            dbc.Button("Search", id="study-out-dir-search-btn", color="secondary", size="sm"),
            html.P(id='study-out-dir-status', style={"fontSize": "0.95em", "color": COLORS['gray'], "marginTop": "5px"}),
        ], style={"marginBottom": "18px"}),
        # stat Î™©Î°ù Ìé∏Ïßë
        html.Div([
            html.H5("Edit Stat List", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "10px"}),
            dcc.Textarea(id='stat-list-input', value='\n'.join(STATS_TO_FIND), style={"width": "100%", "height": "80px", "borderColor": COLORS['secondary']}),
            dbc.Button("Apply", id="stat-list-apply-btn", color="secondary", size="sm", className="mt-2 me-2"),
            dbc.Button("Reset to Default", id="stat-list-reset-btn", color="light", size="sm", className="mt-2"),
            html.P(id='stat-list-status', style={"fontSize": "0.95em", "color": COLORS['gray'], "marginTop": "5px"}),
        ], style={"marginBottom": "18px"}),
        # Section 1: Baseline Directory
        html.Div([
            html.H5("1. Select Baseline Directory", 
                    style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            html.Div([
                html.P("This tool analyzes the following stats:", 
                       style={"fontWeight": "600", "color": COLORS['dark'], "marginBottom": "10px"}),
                html.Ul(id='baseline-stats-list', children=[html.Li(stat, style={"color": COLORS['dark'], "marginBottom": "5px"}) for stat in STATS_TO_FIND], 
                       style={"backgroundColor": COLORS['light'], "padding": "10px", "borderRadius": "5px"}),
                html.P("Click 'Start Analysis' to automatically aggregate and compare the above stats for the selected directories.", 
                       style={"fontSize": "0.95em", "color": COLORS['gray'], "fontStyle": "italic"})
            ], className="mb-4"),
            dcc.Dropdown(id='baseline-dropdown', options=dir_options, 
                        placeholder="Select the baseline directory...",
                        style={"borderColor": COLORS['secondary']})
        ], style={"marginBottom": "25px"}),
        
        # Section 2: Target Directories
        html.Div([
            html.H5("2. Select Target Directories", 
                    style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            dcc.Checklist(id='target-checklist', options=dir_options, 
                         labelClassName="me-3", inputClassName="me-1",
                         style={"color": COLORS['dark']})
        ], style={"marginBottom": "25px"}),
        
        # Section 3: Manual Paths
        html.Div([
            html.H5("3. (Optional) Add Directories Manually", 
                    style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            dbc.Textarea(id="manual-path-input", 
                        placeholder="Enter directory paths not listed above, one per line...", 
                        style={'height': '80px', "borderColor": COLORS['secondary']})
        ], style={"marginBottom": "25px"}),

        # Section 4: Statistical Test Options
        html.Div([
            html.H5("4. Statistical Test Options", 
                    style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            # Ï∂îÍ∞Ä: ÌÜµÍ≥Ñ ÏòµÏÖò ÌôúÏÑ±Ìôî Ï≤¥ÌÅ¨Î∞ïÏä§
            dbc.Checkbox(
                id='enable-statistical-options',
                value=False,
                label="Enable statistical test & effect size analysis",
                style={"marginBottom": "10px", "fontWeight": "600", "color": COLORS['secondary']}
            ),
            html.Div([
                html.Label("Significance Level (Œ±):", style={"fontWeight": "600", "marginRight": "10px"}),
                dcc.Slider(
                    id='alpha-slider',
                    min=0.01, max=0.2, step=0.01, value=0.05,
                    marks={0.01: '0.01', 0.05: '0.05', 0.1: '0.1', 0.2: '0.2'},
                    tooltip={"placement": "bottom", "always_visible": False},
                    included=False,
                    updatemode='drag',
                    className="mb-2",
                    disabled=True  # Í∏∞Î≥∏ ÎπÑÌôúÏÑ±Ìôî
                ),
            ], style={"marginBottom": "18px"}),
            html.Div([
                html.Label("Multiple Comparison Correction:", style={"fontWeight": "600", "marginRight": "10px"}),
                dcc.Dropdown(
                    id='correction-method-dropdown',
                    options=[
                        {"label": "None", "value": "none"},
                        {"label": "Bonferroni", "value": "bonferroni"},
                        {"label": "Holm", "value": "holm"},
                        {"label": "Benjamini-Hochberg (FDR)", "value": "fdr_bh"}
                    ],
                    value="none",
                    clearable=False,
                    style={"width": "70%"},
                    disabled=True  # Í∏∞Î≥∏ ÎπÑÌôúÏÑ±Ìôî
                )
            ], style={"marginBottom": "18px"}),
            html.Div([
                html.Label("Effect Size Threshold (Cohen's d):", style={"fontWeight": "600", "marginRight": "10px"}),
                dcc.Slider(
                    id='effect-size-threshold-slider',
                    min=0, max=2, step=0.05, value=0,
                    marks={0: '0', 0.2: '0.2', 0.5: '0.5', 0.8: '0.8', 1.0: '1.0', 1.5: '1.5', 2.0: '2.0'},
                    tooltip={"placement": "bottom", "always_visible": False},
                    included=False,
                    updatemode='drag',
                    className="mb-2",
                    disabled=True  # Í∏∞Î≥∏ ÎπÑÌôúÏÑ±Ìôî
                ),
            ])
        ], style={"marginBottom": "25px"}),

        # Analysis Button
        dbc.Button("üöÄ Start Analysis", id="run-button", 
                  color="primary", className="my-3 w-100",
                  style={"backgroundColor": COLORS['secondary'], "borderColor": COLORS['secondary'], 
                         "fontWeight": "600", "fontSize": "1.1em", "padding": "12px"}),
        dbc.Tooltip(
            "Click to start analyzing the selected directories. This will process all .out files and generate comparison reports.",
            target="run-button",
            placement="top"
        ),
        
        # Progress and Info
        html.Div(id="progress-wrapper", 
                children=[dbc.Progress(id="progress-bar", value=100, striped=True, animated=True)], 
                style={'display': 'none'}),
        html.Div(id="analysis-info-start", className="mt-3"),
        html.Div(id="analysis-info-complete", className="mt-3"),
        # Footer
        html.Footer([
            html.Hr(style={"borderColor": COLORS['light'], "margin": "30px 0"}),
            dbc.Row([
                dbc.Col([
                    html.Div([
                        html.Span("Monaco Simulation Analyzer ‚Äî Created by dong63.ma", 
                                  style={"color": COLORS['primary'], "fontWeight": "600", "marginRight": "15px"}),
                        html.Span("| Version: v1.0.0", 
                                  style={"color": COLORS['gray'], "marginRight": "15px"}),
                        html.Span("| Last updated: 2025-07-21", 
                                  style={"color": COLORS['gray'], "marginRight": "15px"}),
                        html.Span(f"| Python {sys.version_info.major}.{sys.version_info.minor} | Dash {dash.__version__} | Plotly {plotly.__version__}", 
                                  style={"color": COLORS['gray']})
                    ], style={"textAlign": "center", "fontSize": "0.95em"})
                ], width=12)
            ])
        ])
    ])
], style={"border": f"1px solid {COLORS['light']}", "boxShadow": "0 2px 10px rgba(0,0,0,0.1)"})

# --- percentage-change-tab ÏÉÅÎã® ÏòµÏÖò UI Ï∂îÍ∞Ä ---
stat_options = [{'label': stat, 'value': stat} for stat in STATS_TO_FIND]

app.layout = dbc.Container([
    dbc.Row([
        # Sidebar (Ï¢åÏ∏°) - Ï†ëÌûò Í∞ÄÎä•
        dbc.Col([
            # Ï†ëÌûò Î≤ÑÌäº (Ìï≠ÏÉÅ Î≥¥ÏûÑ)
            dbc.Row([
                dbc.Col([
                    dbc.Button("‚óÄ", id="sidebar-toggle", color="light", size="sm", 
                              style={"backgroundColor": COLORS['white'], "borderColor": COLORS['gray'], 
                                     "color": COLORS['dark'], "fontWeight": "bold", "float": "right"})
                ], width=12, className="text-end mb-2")
            ]),
            # ÏÇ¨Ïù¥ÎìúÎ∞î Ìó§Îçî (Ï†ëÌûò Í∞ÄÎä•)
            dbc.Collapse([
                html.H2("Options", className="display-6 mb-3", style={"color": COLORS['primary'], "fontWeight": "700"}),
                html.Hr(),
            ], id="sidebar-header", is_open=True),
            # ÏÇ¨Ïù¥ÎìúÎ∞î ÎÇ¥Ïö© (Ï†ëÌûò Í∞ÄÎä•)
            dbc.Collapse([
                controls,
                # ÎèÑÏõÄÎßê Î≤ÑÌäº Ï∂îÍ∞Ä
                html.Hr(className="my-4"),
                dbc.Button("‚ùì Help Guide", id="help-button", color="info", size="lg", className="w-100",
                          style={"backgroundColor": COLORS['info'], "borderColor": COLORS['info'], "fontWeight": "600"}),
            ], id="sidebar-content", is_open=True),
        ], id="sidebar-col", width=3, style={
            "backgroundColor": COLORS['light'],
            "minHeight": "100vh",
            "padding": "30px 15px",
            "boxShadow": "2px 0 8px rgba(0,0,0,0.04)",
            "transition": "all 0.3s ease"
        }),
        # Main content (Ïö∞Ï∏°) - Î∞òÏùëÌòï
        dbc.Col([
            # Header
            html.H1("üìä Monaco Simulation Results Analyzer", 
                    className="text-center mb-3",
                    style={"color": COLORS['primary'], "fontWeight": "700", "fontSize": "2.5em"}),
            html.P("Advanced simulation data analysis and comparison dashboard", 
                   className="text-center mb-4",
                   style={"color": COLORS['gray'], "fontSize": "1.1em", "fontStyle": "italic"}),
            # Save HTML Button (Ïò§Î•∏Ï™Ω ÏÉÅÎã®, ÏûëÍ≤å)
            html.Div([
                dbc.Button(
                    "üíæ Save as HTML", id="save-html-btn",
                    color="secondary", size="sm", outline=True,
                    className="float-end mt-2 me-2",
                    style={"fontWeight": "600", "boxShadow": "0 1px 4px rgba(0,0,0,0.07)"}
                ),
                dbc.Tooltip(
                    "Save the current dashboard view as an HTML file (including graphs, filters, etc.)",
                    target="save-html-btn",
                    placement="left"
                ),
                html.Div(id="save-status", className="float-end me-2", style={"fontSize": "0.95em", "marginTop": "2.5rem"})
            ], style={"minHeight": "40px", "position": "relative"}),
            # Main Tabs
            dbc.Tabs(id="tabs-container", children=[
                dbc.Tab(html.Div(id="absolute-values-tab"), label="üìà Absolute Values", 
                        tab_id="absolute", label_style={"color": COLORS['primary'], "fontWeight": "600"}),
                dbc.Tab(html.Div(id="percentage-change-tab"), label="üìä Performance Change", 
                        tab_id="change", label_style={"color": COLORS['primary'], "fontWeight": "600"}),
            ], style={"marginBottom": "30px"}),
            # Stores (hidden)
            dcc.Store(id='job-start-time-store'),
            dcc.Store(id='summary-data-store'),
            dcc.Store(id='change-data-store'),
            dcc.Store(id='dir-names-store'),
            dcc.Store(id='run-change-data-store'),
            dcc.Store(id='analysis-meta-store'),
            dcc.Interval(id='progress-interval', interval=1000, disabled=True),
            dcc.Store(id='stats-store', data=STATS_TO_FIND),
            dcc.Store(id='stat-matched-keys-store'), # Ï∂îÍ∞Ä: stat-matched-keys-store
            dcc.Store(id='analysis-complete-store'), # Î∂ÑÏÑù ÏôÑÎ£å Ï†ÑÏö© Store
            dcc.Store(id='study-out-dir-store', data=STUDY_OUT_DIR), # Ï∂îÍ∞Ä: study_out_dir Store
            # Footer
            html.Footer([
                html.Hr(style={"borderColor": COLORS['light'], "margin": "30px 0"}),
                dbc.Row([
                    dbc.Col([
                        html.Div([
                            html.Span("Monaco Simulation Analyzer ‚Äî Created by dong63.ma", 
                                      style={"color": COLORS['primary'], "fontWeight": "600", "marginRight": "15px"}),
                            html.Span("| Version: v1.0.0", 
                                      style={"color": COLORS['gray'], "marginRight": "15px"}),
                            html.Span("| Last updated: 2025-01-20", 
                                      style={"color": COLORS['gray'], "marginRight": "15px"}),
                            html.Span(f"| Python {sys.version_info.major}.{sys.version_info.minor} | Dash {dash.__version__} | Plotly {plotly.__version__}", 
                                      style={"color": COLORS['gray']})
                        ], style={"textAlign": "center", "fontSize": "0.95em"})
                    ], width=12)
                ])
            ])
        ], width=9, style={"padding": "30px 30px", "backgroundColor": COLORS['white']})
    ], className="g-0", style={"minHeight": "100vh"}),
    
    # ÎèÑÏõÄÎßê Î™®Îã¨
    dbc.Modal([
        dbc.ModalHeader([
            dbc.ModalTitle("üìñ Monaco Simulation Analyzer - User Guide", 
                           style={"color": COLORS['primary'], "fontWeight": "600"})
        ], style={"backgroundColor": COLORS['light']}),
        dbc.ModalBody([
            html.H5("üöÄ Quick Start Guide", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            html.Ol([
                html.Li([
                    html.Strong("Select Baseline Directory: "),
                    "Choose the reference directory containing your baseline simulation results (.out files)"
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Select Target Directories: "),
                    "Choose one or more directories to compare against the baseline"
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Add Manual Paths (Optional): "),
                    "Enter additional directory paths not listed in the dropdown"
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Edit Stat List: "),
                    "You can edit the stat list directly in the sidebar, or by editing stats.txt in the project folder."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Start Analysis: "),
                    "Click the button to begin processing and comparing results"
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("View Results: "),
                    "Explore absolute values and performance changes in the tabs. In the 'Performance Change' tab, you can interpret statistical significance and effect size for each metric."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Statistical Options: "),
                    "Use the sidebar to adjust significance level (Œ±), multiple comparison correction, and effect size (Cohen's d) threshold."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Save as HTML: "),
                    "Click the 'Save as HTML' button (top right) to save the current dashboard view‚Äîincluding all graphs, filters, and tables‚Äîas a static HTML file. The file will be named 'dashboard_snapshot_YYYYMMDD_HHMMSS.html'. After saving, a toast notification will appear at the bottom right."
                ], style={"marginBottom": "10px"})
            ], style={"marginBottom": "20px"}),

            html.H5("üìÇ Data & Environment", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            html.Ul([
                html.Li([
                    html.Strong("Analysis Root Directory: "),
                    "You can set the analysis root directory using the environment variable STUDY_OUT_DIR. "
                    "If not set, the current working directory is used. Example:",
                    html.Br(),
                    html.Code("export STUDY_OUT_DIR=/path/to/your/results", style={"fontSize": "0.95em"})
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong(".out File Placement: "),
                    "Place your simulation .out files in subdirectories under the analysis root. The app will automatically discover .out files in all subdirectories up to depth 5."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Stat List Editing: "),
                    "Edit the stat list in the sidebar or by modifying stats.txt. Changes are reflected immediately after applying."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Info Area: "),
                    "When you start analysis, the info area will show the target directories and start time. When analysis completes, it will show elapsed time and cache info."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Cache & Performance: "),
                    "File-level caching is used for fast repeated analysis. If you have a very large/deep directory tree, initial loading may take longer."
                ], style={"marginBottom": "10px"}),
                html.Li([
                    html.Strong("Footer Info: "),
                    "The footer shows the current version, last updated date, Python/Dash/Plotly versions, and environment variable usage."
                ], style={"marginBottom": "10px"})
            ], style={"marginBottom": "20px"}),

            html.H5("üìä Understanding Results", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            html.Ul([
                html.Li([
                    html.Strong("Absolute Values: "),
                    "Raw performance metrics for each directory"
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Performance Change Table: "),
                    "Shows the percentage change, adjusted p-value (p-adj), and effect size (Cohen's d) for each Subgroup/Stat."
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Statistical Significance (‚òÖ): "),
                    "If the adjusted p-value (p-adj) is less than Œ±, a star (‚òÖ) is shown next to the value, indicating a statistically significant change."
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Effect Size (Cohen's d): "),
                    "Quantifies the magnitude of the difference. Typical interpretation: d ‚âà 0.2 (small), d ‚âà 0.5 (medium), d ‚âà 0.8+ (large)."
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Effect Size Threshold: "),
                    "Use the slider to filter for changes with a minimum effect size. Only values with d above the threshold are considered practically meaningful."
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Color Coding: "),
                    "Cells are colored by the magnitude and direction of change (green/red pastel). No additional color is used for significance."
                ], style={"marginBottom": "8px"}),
                html.Li([
                    html.Strong("Export: "),
                    "You can export the table as CSV for further analysis."
                ], style={"marginBottom": "8px"})
            ], style={"marginBottom": "20px"}),

            html.H5("‚öôÔ∏è Features", style={"color": COLORS['primary'], "fontWeight": "600", "marginBottom": "15px"}),
            html.Ul([
                html.Li("File-level caching for fast repeated analysis"),
                html.Li("Export tables as CSV"),
                html.Li("Save dashboard as HTML snapshot (current view, including all filters and graphs)"),
                html.Li("Statistical significance (p-adj) and effect size (Cohen's d) for robust interpretation"),
                html.Li("Responsive design for all screen sizes"),
                html.Li("Customizable stat list via stats.txt file")
            ])
        ]),
        dbc.ModalFooter([
            dbc.Button("Close", id="close-help", className="ms-auto", 
                      style={"backgroundColor": COLORS['secondary'], "borderColor": COLORS['secondary']})
        ])
    ], id="help-modal", is_open=False, size="lg")
], fluid=True)

# --- ÏΩúÎ∞± Ìï®ÏàòÎì§ ---
# [ÏÑ§Î™Ö] ÏÇ¨Ïö©Ïûê Ïù∏ÌÑ∞ÎûôÏÖò(Î∂ÑÏÑù ÏãúÏûë, ÏßÑÌñâ/ÏôÑÎ£å ÌëúÏãú, Îç∞Ïù¥ÌÑ∞ Î∂ÑÏÑù, ÏãúÍ∞ÅÌôî Îì±)Ïóê Îî∞Îùº ÎèôÏ†ÅÏúºÎ°ú UIÎ•º ÏóÖÎç∞Ïù¥Ìä∏ÌïòÎäî Dash ÏΩúÎ∞± Ìï®ÏàòÎì§ÏûÖÎãàÎã§.

# ÌÜµÍ≥Ñ ÏòµÏÖò ÌôúÏÑ±Ìôî Ï≤¥ÌÅ¨Î∞ïÏä§Ïóê Îî∞Îùº Ïä¨ÎùºÏù¥Îçî/ÎìúÎ°≠Îã§Ïö¥ ÌôúÏÑ±Ìôî
@app.callback(
    [Output('alpha-slider', 'disabled'),
     Output('correction-method-dropdown', 'disabled'),
     Output('effect-size-threshold-slider', 'disabled')],
    Input('enable-statistical-options', 'value')
)
def toggle_statistical_options(enabled):
    disabled = not enabled
    return [disabled, disabled, disabled]

# ÏΩúÎ∞± 1: 'Î∂ÑÏÑù ÏãúÏûë' Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú, Ïä§ÌÜ†Ïñ¥ Ï¥àÍ∏∞Ìôî, ÏßÑÌñâÎ•† Î∞î ÌôúÏÑ±Ìôî, Î≤ÑÌäº ÎπÑÌôúÏÑ±Ìôî
@app.callback(
    [Output('job-start-time-store', 'data'),
     Output('progress-interval', 'disabled'),
     Output('progress-wrapper', 'style'),
     Output('run-button', 'disabled'),
     Output('summary-data-store', 'data', allow_duplicate=True),
     Output('change-data-store', 'data', allow_duplicate=True),
     Output('dir-names-store', 'data', allow_duplicate=True),
     Output('analysis-meta-store', 'data')],
    Input('run-button', 'n_clicks'),
    State('baseline-dropdown', 'value'),
    State('target-checklist', 'value'),
    State('manual-path-input', 'value'),
    State('study-out-dir-store', 'data'), # Ï∂îÍ∞Ä
    prevent_initial_call=True,
)
def start_analysis_job(n_clicks, baseline_dir, target_dirs_checked, manual_paths, study_out_dir):
    import datetime, time, os
    start_time = time.time()
    def resolve_path(p):
        if not p:
            return None
        if os.path.isabs(p):
            return p
        return str(Path(study_out_dir) / p)
    dirs = [resolve_path(baseline_dir)] if baseline_dir else []
    if target_dirs_checked:
        dirs += [resolve_path(p) for p in target_dirs_checked]
    if manual_paths:
        dirs += [resolve_path(p.strip()) for p in manual_paths.split('\n') if p.strip()]
    dirs = [d for d in dict.fromkeys(dirs) if d]
    start_str = datetime.datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')
    meta = {'dirs': dirs, 'start_str': start_str}
    # summary-data-store.dataÎ•º Ìï≠ÏÉÅ NoneÏúºÎ°ú Î¶¨ÏÖã
    return start_time, False, {'display': 'block'}, True, None, None, None, meta

# ÏΩúÎ∞± 2: [Î∞±Í∑∏ÎùºÏö¥Îìú] Ïã§Ï†ú Î∂ÑÏÑùÏùÑ ÏàòÌñâÌïòÍ≥† Í≤∞Í≥ºÎ•º dcc.StoreÏóê Ï†ÄÏû•
def cohens_d(x, y):
    # Îëê ÏßëÎã®Ïùò Cohen's d
    nx, ny = len(x), len(y)
    if nx < 2 or ny < 2:
        return np.nan
    mean_x, mean_y = np.mean(x), np.mean(y)
    s1, s2 = np.var(x, ddof=1), np.var(y, ddof=1)
    pooled_std = np.sqrt(((nx - 1) * s1 + (ny - 1) * s2) / (nx + ny - 2))
    if pooled_std == 0:
        return 0.0
    return (mean_x - mean_y) / pooled_std

# 2. stat Î™©Î°ù Ìé∏Ïßë ÏΩúÎ∞±
@app.callback(
    [Output('stat-list-status', 'children'),
     Output('stat-list-input', 'value'),
     Output('stats-store', 'data')],
    [Input('stat-list-apply-btn', 'n_clicks'),
     Input('stat-list-reset-btn', 'n_clicks')],
    State('stat-list-input', 'value'),
    prevent_initial_call=True
)
def update_stats_list(apply_n, reset_n, stat_text):
    ctx = dash.callback_context
    if not ctx.triggered:
        raise dash.exceptions.PreventUpdate
    btn_id = ctx.triggered[0]['prop_id'].split('.')[0]
    if btn_id == 'stat-list-reset-btn':
        default_stats = load_stats_to_find('stats.txt')
        return "‚úÖ Stat list reset to default.", '\n'.join(default_stats), default_stats
    # Apply Î≤ÑÌäº
    stats = [s.strip() for s in stat_text.splitlines() if s.strip()]
    if not stats:
        return "‚ùå Please enter at least one stat.", stat_text, dash.no_update
    return f"‚úÖ Stat list updated: {', '.join(stats)}", '\n'.join(stats), stats

# stats-store Î≥ÄÍ≤Ω Ïãú Baseline Directory stat Î¶¨Ïä§Ìä∏ ÎèôÏ†Å ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞±
@app.callback(
    Output('baseline-stats-list', 'children'),
    [Input('stats-store', 'data'),
     Input('stat-matched-keys-store', 'data')]
)
def update_baseline_stats_list(stats, matched_keys):
    if not stats:
        return []
    items = []
    for stat in stats:
        keys = matched_keys.get(stat, []) if matched_keys else []
        tooltip = f"Matched keys: {', '.join(keys)}" if keys else "No matched keys yet. Will be shown after analysis."
        items.append(
            html.Li([
                html.Span(stat, id={'type': 'stat-tooltip', 'stat': stat}, style={"color": COLORS['dark'], "marginBottom": "5px"}),
                dbc.Tooltip(tooltip, target={'type': 'stat-tooltip', 'stat': stat}, placement="right")
            ], style={"marginBottom": "5px"})
        )
    return items

# 3. Î∂ÑÏÑù ÏΩúÎ∞±ÏóêÏÑú stats-storeÏùò Í∞íÏùÑ ÏÇ¨Ïö©
@app.callback(
    [Output('summary-data-store', 'data'),
     Output('change-data-store', 'data'),
     Output('dir-names-store', 'data'),
     Output('run-change-data-store', 'data'),
     Output('stat-matched-keys-store', 'data'),
     Output('analysis-complete-store', 'data')],
    Input('run-button', 'n_clicks'),
    [State("baseline-dropdown", "value"),
     State("target-checklist", "value"),
     State("manual-path-input", "value"),
     State("alpha-slider", "value"),
     State("correction-method-dropdown", "value"),
     State("effect-size-threshold-slider", "value"),
     State('stats-store', 'data'),
     State('enable-statistical-options', 'value'),
     State('study-out-dir-store', 'data')], # Ï∂îÍ∞Ä
    background=True,
    manager=background_callback_manager,
    prevent_initial_call=True,
)
def run_analysis_callback(set_progress, baseline_dir, target_dirs_checked, manual_paths, alpha, correction_method, effect_size_threshold, stats_to_find, enable_statistical_options, study_out_dir):
    import os
    def resolve_path(p):
        if not p:
            return None
        if os.path.isabs(p):
            return p
        return str(Path(study_out_dir) / p)
    if not baseline_dir: return dash.no_update, dash.no_update, dash.no_update, dash.no_update, dash.no_update, dash.no_update
    targets = set(target_dirs_checked) if target_dirs_checked else set()
    if manual_paths:
        for path in manual_paths.split('\n'):
            if path.strip(): targets.add(path.strip())
    targets.discard(baseline_dir)
    if not targets: return dash.no_update, dash.no_update, dash.no_update, dash.no_update, dash.no_update, dash.no_update
    if not stats_to_find:
        stats_to_find = STATS_TO_FIND
    root_dirs = [resolve_path(baseline_dir)] + sorted([resolve_path(p) for p in targets])
    dir_names = [os.path.basename(p) for p in root_dirs]
    summaries = []
    all_matched_keys = {stat: set() for stat in stats_to_find}
    for dir_path in root_dirs:
        df, matched_keys = analyze_directory(Path(dir_path), stats_to_find)
        summaries.append(df)
        for stat, keys in matched_keys.items():
            all_matched_keys[stat].update(keys)
    summaries_json = [s.to_json(orient='split') if s is not None else None for s in summaries]
    change_dfs_json = []
    run_change_dfs_json = []
    if summaries[0] is not None:
        for i in range(1, len(summaries)):
            if summaries[i] is not None:
                base = summaries[0].groupby(['Subgroup', 'Stat'])['Value'].mean().reset_index()
                targ = summaries[i].groupby(['Subgroup', 'Stat'])['Value'].mean().reset_index()
                merged = pd.merge(targ, base, on=['Subgroup', 'Stat'], suffixes=('_target', '_baseline'))
                merged['Change'] = ((merged['Value_target'] - merged['Value_baseline']) / merged['Value_baseline']) * 100
                if enable_statistical_options:
                    # --- p-value, effect size Í≥ÑÏÇ∞ ---
                    pvals = []
                    ds = []
                    for _, row in merged.iterrows():
                        sub, stat = row['Subgroup'], row['Stat']
                        base_vals = summaries[0][(summaries[0]['Subgroup'] == sub) & (summaries[0]['Stat'] == stat)]['Value'].values
                        targ_vals = summaries[i][(summaries[i]['Subgroup'] == sub) & (summaries[i]['Stat'] == stat)]['Value'].values
                        if len(base_vals) > 1 and len(targ_vals) > 1:
                            try:
                                stat_res = ttest_ind(base_vals, targ_vals, equal_var=False, nan_policy='omit')
                                pval = stat_res.pvalue
                                d = cohens_d(targ_vals, base_vals)
                            except Exception:
                                pval = np.nan
                                d = np.nan
                        else:
                            pval = np.nan
                            d = np.nan
                        pvals.append(pval)
                        ds.append(d)
                    merged['p-value'] = pvals
                    merged['effect_size'] = ds
                    # --- Îã§Ï§ëÎπÑÍµê Î≥¥Ï†ï ---
                    if correction_method and correction_method != 'none':
                        mask = ~pd.isna(merged['p-value'])
                        pvals_arr = merged.loc[mask, 'p-value'].values
                        reject, pvals_corr, _, _ = multipletests(pvals_arr, alpha=alpha, method=correction_method)
                        merged.loc[mask, 'p-adj'] = pvals_corr
                        merged.loc[mask, 'signif'] = reject
                    else:
                        merged['p-adj'] = merged['p-value']
                        merged['signif'] = merged['p-value'] < alpha
                    merged['star'] = merged['signif'].apply(lambda x: '*' if x else '')
                # ÌîºÎ≤ó: Î≥ÄÌôîÏú®, p-adj, Î≥ÑÌëú, effect_size
                pivot_change = merged.pivot(index='Subgroup', columns='Stat', values='Change').reset_index().round(2)
                if enable_statistical_options:
                    pivot_padj = merged.pivot(index='Subgroup', columns='Stat', values='p-adj').reset_index().round(4)
                    pivot_star = merged.pivot(index='Subgroup', columns='Stat', values='star').reset_index()
                    pivot_d = merged.pivot(index='Subgroup', columns='Stat', values='effect_size').reset_index().round(3)
                columns = ['Subgroup']
                for stat in pivot_change.columns:
                    if stat != 'Subgroup':
                        columns.append((stat, 'Change'))
                        if enable_statistical_options:
                            columns.extend([(stat, 'p-adj'), (stat, 'Signif'), (stat, 'd')])
                data = []
                for idx in range(len(pivot_change)):
                    row = {'Subgroup': pivot_change.loc[idx, 'Subgroup']}
                    for stat in pivot_change.columns:
                        if stat == 'Subgroup':
                            continue
                        row[(stat, 'Change')] = pivot_change.loc[idx, stat]
                        if enable_statistical_options:
                            row[(stat, 'p-adj')] = pivot_padj.loc[idx, stat]
                            row[(stat, 'Signif')] = pivot_star.loc[idx, stat]
                            row[(stat, 'd')] = pivot_d.loc[idx, stat]
                    data.append(row)
                table_df = pd.DataFrame(data, columns=columns)
                # ÌèâÍ∑†(min) Ìñâ Ï∂îÍ∞Ä
                stat_cols = [col for col in table_df.columns if col != 'Subgroup' and (col[1] == 'Change')]
                min_row = {'Subgroup': 'mean'}
                for stat_col in stat_cols:
                    min_row[stat_col] = table_df[stat_col].mean()
                table_df = pd.concat([table_df, pd.DataFrame([min_row])], ignore_index=True)
                change_dfs_json.append(table_df.to_json(orient='split'))
                # runÎ≥Ñ Î≥ÄÌôîÏú® Í≥ÑÏÇ∞ (Í∏∞Ï°¥Í≥º ÎèôÏùº)
                base_run = summaries[0][['Subgroup', 'Run', 'Stat', 'Value']].copy()
                targ_run = summaries[i][['Subgroup', 'Run', 'Stat', 'Value']].copy()
                run_merged = pd.merge(targ_run, base_run, on=['Subgroup', 'Run', 'Stat'], suffixes=('_target', '_baseline'))
                run_merged['Change'] = ((run_merged['Value_target'] - run_merged['Value_baseline']) / run_merged['Value_baseline']) * 100
                run_change_dfs_json.append(run_merged.to_json(orient='split'))
            else:
                change_dfs_json.append(None)
                run_change_dfs_json.append(None)
    # ÎßàÏßÄÎßâ Output: Î∂ÑÏÑù ÏôÑÎ£å Ïã†Ìò∏ True
    return summaries_json, change_dfs_json, dir_names, run_change_dfs_json, {stat: list(keys) for stat, keys in all_matched_keys.items()}, True

# ÏΩúÎ∞± 3: [Ïã§ÏãúÍ∞Ñ ÏóÖÎç∞Ïù¥Ìä∏] IntervalÏùÑ ÌÜµÌï¥ ÏàòÌñâ ÏãúÍ∞Ñ ÏóÖÎç∞Ïù¥Ìä∏ Î∞è ÏôÑÎ£å Ï≤òÎ¶¨
@app.callback(
    [Output('progress-bar', 'label'),
     Output('progress-interval', 'disabled', allow_duplicate=True),
     Output('progress-wrapper', 'style', allow_duplicate=True),
     Output('run-button', 'disabled', allow_duplicate=True)],
    [Input('progress-interval', 'n_intervals'),
     Input('summary-data-store', 'data')],
    State('job-start-time-store', 'data'),
    prevent_initial_call=True,
)
def update_progress_label(n_intervals, summary_data, start_time):
    if summary_data:
        elapsed_time = time.time() - start_time
        td = datetime.timedelta(seconds=int(elapsed_time))
        label = f"Analysis completed! (Total elapsed time: {td})"
        return label, True, {'display': 'none'}, False
    elapsed_time = time.time() - start_time
    td = datetime.timedelta(seconds=int(elapsed_time))
    label = f"Analysis in progress... (Elapsed time: {td})"
    return label, False, {'display': 'block'}, True

# ÏΩúÎ∞± 4: StoreÏùò Ï†àÎåÄÍ∞í Îç∞Ïù¥ÌÑ∞Î°ú 'Ï†àÎåÄÍ∞í Î∂ÑÏÑù' ÌÉ≠ ÎÇ¥Ïö©ÏùÑ ÏÉùÏÑ±
@app.callback(
    Output("absolute-values-tab", "children"),
    [Input("summary-data-store", "data"),
     State("dir-names-store", "data"),
     State('stats-store', 'data'),
     State('stat-matched-keys-store', 'data')]
)
def update_absolute_values_tab(summaries_json, dir_names, stats_to_find, matched_keys):
    if summaries_json is None:
        return "Please start analysis or wait for it to complete."
    output_components = []
    for i, summary_json in enumerate(summaries_json):
        if summary_json is None:
            continue
        dir_name = dir_names[i]
        summary_df = pd.read_json(summary_json, orient='split')
        output_components.append(html.H3(f"üìÅ {dir_name} Absolute Value Analysis", className="mt-4"))
        # ÌååÏùºÎ™Ö ÏÉùÏÑ±
        now_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        # subgroupÎ≥Ñ statÎ≥Ñ ÌèâÍ∑† ÌÖåÏù¥Î∏î
        if {'Subgroup', 'Stat', 'Value'}.issubset(summary_df.columns):
            pivot_df = summary_df.groupby(['Subgroup', 'Stat'])['Value'].mean().reset_index()
            table_df = pivot_df.pivot(index='Subgroup', columns='Stat', values='Value')
            # stat-list Í∏∞Ï§Ä Ïª¨Îüº Î≥¥Ïû•
            for stat in stats_to_find:
                if stat not in table_df.columns:
                    table_df[stat] = np.nan
            table_df = table_df[stats_to_find]
            table_df = table_df.reset_index().round(4)
            # ÌèâÍ∑†(min) Ìñâ Ï∂îÍ∞Ä
            stat_cols = [col for col in table_df.columns if col != 'Subgroup']
            min_row = {'Subgroup': 'mean'}
            for stat in stat_cols:
                min_row[stat] = table_df[stat].mean()  # ÌèâÍ∑†, minÏúºÎ°ú Î∞îÍæ∏Î†§Î©¥ .min()
            table_df = pd.concat([table_df, pd.DataFrame([min_row])], ignore_index=True)
        else:
            table_df = summary_df.round(4)
        output_components.extend([
            html.H4("Data Table", className="mt-3"),
            dash_table.DataTable(
                data=table_df.round(4).to_dict('records'),
                style_table={'overflowX': 'auto'},
                style_cell={'textAlign': 'center', 'minWidth': '80px', 'maxWidth': '100px', 'width': '90px'},
                export_format='csv',
                export_headers='display',
            ),
            # Stat-to-actual-key mapping summary
            html.Div([
                html.H6("Stat-to-actual-key mapping:"),
                html.Ul([
                    html.Li(f"{stat}: {', '.join(matched_keys.get(stat, [])) or 'None'}") for stat in stats_to_find
                ])
            ], style={"fontSize": "0.95em", "color": "#888", "marginTop": "10px"})
        ])
        # groupÎ≥Ñ, statÎ≥Ñ Í∑∏ÎûòÌîÑ (subgroupÎ≥Ñ ÌèâÍ∑†)
        if {'Subgroup', 'Stat', 'Value'}.issubset(summary_df.columns):
            stat_graphs = []
            for stat in stats_to_find:
                stat_df = summary_df.groupby(['Subgroup', 'Stat'])['Value'].mean().reset_index()
                stat_df = stat_df[stat_df['Stat'] == stat]
                fig = px.bar(stat_df, x='Subgroup', y='Value', title=f"{dir_name} - {stat} (Average)", 
                             labels={'Value': stat, 'Subgroup': 'Subgroup'},
                             color_discrete_sequence=[PLOTLY_COLORS[i % len(PLOTLY_COLORS)]])
                fig.update_layout(title_x=0.5, 
                                 plot_bgcolor=COLORS['white'],
                                 paper_bgcolor=COLORS['white'],
                                 font={'color': COLORS['dark']})
                stat_graphs.append(dbc.Col(dcc.Graph(figure=fig), width=12, lg=6, xl=4))
            output_components.append(dbc.Row(stat_graphs))
        output_components.append(html.Hr())
    return output_components

# --- ÌååÏä§ÌÖîÌÜ§ ÌûàÌä∏Îßµ ÏÉâÏÉÅ Ìï®Ïàò ---
def get_pastel_gradient_color(value, vmin, vmax):
    if value is None or np.isnan(value):
        return 'white'
    max_abs = max(abs(vmin), abs(vmax), 1e-6)
    ratio = min(abs(value) / max_abs, 1)
    if value > 0:
        # ÎÇòÎ≠áÏûé ÏßÑÎÖπÏÉâ ÌååÏä§ÌÖî: Î∞ùÏùÄ Ïó∞ÎÖπÏÉâ(220,240,220) ~ ÏßÑÎÖπÏÉâ(60,180,90)
        r = int(220 - (160 * ratio))  # 220~60
        g = int(240 - (60 * ratio))   # 240~180
        b = int(220 - (130 * ratio))  # 220~90
        return f'rgb({r},{g},{b})'
    elif value < 0:
        # Î∂âÏùÄ ÌååÏä§ÌÖî: Î∞ùÏùÄ Ïó∞Î∂ÑÌôç(255,220,220) ~ ÏßÑÎπ®Í∞ï(255,100,100)
        r = 255
        g = int(220 - (120 * ratio))  # 220~100
        b = int(220 - (120 * ratio))  # 220~100
        return f'rgb({r},{g},{b})'
    else:
        return 'white'

@app.callback(
    Output("percentage-change-tab", "children"),
    [Input("change-data-store", "data"),
     State("dir-names-store", "data"),
     State("alpha-slider", "value"),
     State("effect-size-threshold-slider", "value"),
     State('stats-store', 'data'),
     State('stat-matched-keys-store', 'data'),
     State('enable-statistical-options', 'value')]
)
def update_percentage_change_tab(change_dfs_json, dir_names, alpha, effect_size_threshold, stats_to_find, matched_keys, enable_statistical_options):
    output_components = []
    if change_dfs_json is None:
        output_components.append("Please start analysis or wait for it to complete.")
        return output_components
    if not change_dfs_json:
        output_components.append("No comparison targets or analysis results.")
        return output_components
    baseline_dir_name = dir_names[0]
    for i, change_json in enumerate(change_dfs_json):
        target_dir_name = dir_names[i+1]
        comp_title = f"'{baseline_dir_name}' (Baseline) vs. '{target_dir_name}'"
        now_str = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
        output_components.extend([
            html.Hr(className="my-4"),
            html.H2(f"üîç Comparison: {comp_title}", className="mt-4")
        ])
        if change_json is None:
            output_components.append(html.P("Comparison failed for target directory."))
            continue
        table_df = pd.read_json(change_json, orient='split')
        # MultiIndex ‚Üí Îã®Ïùº Ïù∏Îç±Ïä§(str)
        table_df.columns = [
            col if col == 'Subgroup' else f"{col[0]}_{col[1]}"
            for col in table_df.columns
        ]
        # stat-list Í∏∞Ï§Ä Ïª¨Îüº Î≥¥Ïû•
        for stat in stats_to_find:
            if f"{stat}_Change" not in table_df.columns:
                table_df[f"{stat}_Change"] = np.nan
            if enable_statistical_options:
                if f"{stat}_p-adj" not in table_df.columns:
                    table_df[f"{stat}_p-adj"] = np.nan
                if f"{stat}_d" not in table_df.columns:
                    table_df[f"{stat}_d"] = np.nan
        # Ïª¨Îüº ÏàúÏÑú ÎßûÏ∂îÍ∏∞
        columns = ['Subgroup']
        for stat in stats_to_find:
            columns.append(f"{stat}_Change")
            if enable_statistical_options:
                columns.extend([f"{stat}_p-adj", f"{stat}_d"])
        table_df = table_df[columns]
        stat_cols = [col for col in table_df.columns if col != 'Subgroup' and col.endswith('_Change')]
        style_data_conditional = []
        for stat_col in stat_cols:
            stat = stat_col.replace('_Change', '')
            vmin = table_df[stat_col].min()
            vmax = table_df[stat_col].max()
            for irow, row in table_df.iterrows():
                color = get_pastel_gradient_color(row[stat_col], vmin, vmax)
                style_data_conditional.append({
                    'if': {'row_index': irow, 'column_id': stat_col},
                    'backgroundColor': color,
                    'color': 'black'
                })
        # Ïª¨Îüº Ï†ïÏùò
        dash_columns = []
        for stat in stats_to_find:
            dash_columns.append({"name": [stat, 'Change (%)'], "id": f"{stat}_Change", "presentation": "markdown"})
            if enable_statistical_options:
                dash_columns.append({"name": [stat, 'p-adj'], "id": f"{stat}_p-adj"})
                dash_columns.append({"name": [stat, 'd'], "id": f"{stat}_d"})
        dash_columns = [{"name": "Subgroup", "id": "Subgroup"}] + dash_columns
        # Îç∞Ïù¥ÌÑ∞: Î≥ÄÌôîÏú®+Ïú†ÏùòÏÑ± Ïã¨Î≤å(‚òÖ)
        data = []
        for irow, row in table_df.iterrows():
            d = {}
            for col in table_df.columns:
                if col.endswith('_Change'):
                    val = row[col]
                    if enable_statistical_options:
                        padj_col = col.replace('_Change', '_p-adj')
                        d_col = col.replace('_Change', '_d')
                        pval = row[padj_col] if padj_col in table_df.columns else None
                        d_val = row[d_col] if d_col in table_df.columns else None
                        symbol = ''
                        if pd.notna(pval) and pval < alpha:
                            symbol = ' ‚òÖ'
                        if pd.notna(val):
                            d[col] = f"{val:.2f}{symbol}"
                        else:
                            d[col] = ''
                    else:
                        d[col] = f"{val:.2f}" if pd.notna(val) else ''
                elif enable_statistical_options and col.endswith('_p-adj'):
                    val = row[col]
                    d[col] = f"{val:.4f}" if pd.notna(val) else ''
                elif enable_statistical_options and col.endswith('_d'):
                    val = row[col]
                    d[col] = f"{val:.4f}" if pd.notna(val) else ''
                else:
                    d[col] = row[col]
            data.append(d)
        output_components.extend([
            html.H4("Average Performance Change (%)", className="mt-3"),
            dash_table.DataTable(
                id={'type': 'change-table', 'index': i},
                data=data,
                columns=dash_columns,
                style_table={'overflowX': 'auto'},
                style_data_conditional=style_data_conditional,
                style_cell={'textAlign': 'center', 'minWidth': '80px', 'maxWidth': '100px', 'width': '90px'},
                row_selectable='single',
                cell_selectable=True,
                export_format='csv',
                export_headers='display',
            ),
            # ÎìúÎ¶¥Îã§Ïö¥(run-level) Í∑∏ÎûòÌîÑ Ïª®ÌÖåÏù¥ÎÑà Ï∂îÍ∞Ä
            html.Div(id={'type': 'run-level-graph', 'index': i}),
            # Stat-to-actual-key mapping summary
            html.Div([
                html.H6("Stat-to-actual-key mapping:"),
                html.Ul([
                    html.Li(f"{stat}: {', '.join(matched_keys.get(stat, [])) or 'None'}") for stat in stats_to_find
                ])
            ], style={"fontSize": "0.95em", "color": "#888", "marginTop": "10px"})
        ])
        # --- Í∑∏ÎûòÌîÑ Ï∂îÍ∞Ä ---
        figures = []
        for stat in stats_to_find:
            stat_col = f"{stat}_Change"
            graph_df = table_df[['Subgroup', stat_col]].copy()
            graph_df = graph_df[graph_df['Subgroup'] != 'mean']
            graph_df = graph_df.dropna(subset=['Subgroup', stat_col])
            graph_df = graph_df[graph_df['Subgroup'] != '']
            graph_df = graph_df.reset_index(drop=True)
            if not graph_df.empty and len(graph_df['Subgroup']) == len(graph_df[stat_col]):
                fig = px.bar(graph_df, x='Subgroup', y=stat_col, title=f"{stat} Change (%)", 
                             labels={stat_col: 'Change (%)', 'Subgroup': 'Subgroup'},
                             color_discrete_sequence=[PLOTLY_COLORS[i % len(PLOTLY_COLORS)]])
                fig.update_layout(title_x=0.5,
                                 plot_bgcolor=COLORS['white'],
                                 paper_bgcolor=COLORS['white'],
                                 font={'color': COLORS['dark']})
                figures.append(dbc.Col(dcc.Graph(figure=fig), width=12, lg=6, xl=4))
        output_components.append(dbc.Row(figures))
    return output_components

# ÎìúÎ¶¥Îã§Ïö¥: row ÌÅ¥Î¶≠ Ïãú runÎ≥Ñ Î≥ÄÌôîÏú® ÌÖåÏù¥Î∏î(ÌååÏä§ÌÖî ÌûàÌä∏Îßµ Ï†ÅÏö©)
@app.callback(
    Output({'type': 'run-level-graph', 'index': MATCH}, 'children'),
    Input({'type': 'change-table', 'index': MATCH}, 'active_cell'),
    State({'type': 'change-table', 'index': MATCH}, 'data'),
    State('run-change-data-store', 'data'),
    State('dir-names-store', 'data'),
    prevent_initial_call=True,
)
def show_run_level_table(active_cell, table_data, run_change_dfs_json, dir_names):
    if not active_cell or not table_data or not run_change_dfs_json:
        return []
    row = table_data[active_cell['row']]
    subgroup = row.get('Subgroup')
    if not subgroup:
        return []
    ctx = dash.callback_context
    idx = ctx.triggered[0]['prop_id'].split('.')[0]
    idx = eval(idx)['index'] if 'index' in idx else 0
    run_json = run_change_dfs_json[idx] if idx < len(run_change_dfs_json) else None
    if not run_json:
        return []
    run_df = pd.read_json(run_json, orient='split')
    run_df = run_df[run_df['Subgroup'] == subgroup]
    if run_df.empty:
        return html.P("No run-level data for this subgroup.")
    # wide format: Run, stat1, stat2, ...
    pivot_df = run_df.pivot_table(index='Run', columns='Stat', values='Change', aggfunc='mean').reset_index().round(2)
    # ÌååÏä§ÌÖîÌÜ§ ÌûàÌä∏Îßµ Ï†ÅÏö©
    stat_cols = [col for col in pivot_df.columns if col != 'Run']
    style_data_conditional = []
    for stat in stat_cols:
        vmin = pivot_df[stat].min()
        vmax = pivot_df[stat].max()
        for irow, row in pivot_df.iterrows():
            color = get_pastel_gradient_color(row[stat], vmin, vmax)
            style_data_conditional.append({
                'if': {'row_index': irow, 'column_id': stat},
                'backgroundColor': color,
                'color': 'black'
            })
    # ÎìúÎ¶¥Îã§Ïö¥(run-level) ÌÖåÏù¥Î∏î ÌïòÎã®Ïóê ÌèâÍ∑†(min) Ìñâ Ï∂îÍ∞Ä
    min_row = {'Run': 'mean'}
    for stat in stat_cols:
        min_row[stat] = pivot_df[stat].mean()  # ÌèâÍ∑†, minÏúºÎ°ú Î∞îÍæ∏Î†§Î©¥ .min()
    pivot_df = pd.concat([pivot_df, pd.DataFrame([min_row])], ignore_index=True)
    return dash_table.DataTable(
        data=pivot_df.round(4).to_dict('records'),
        columns=[{"name": c, "id": c} for c in pivot_df.columns],
        style_table={'overflowX': 'auto'},
        style_cell={'textAlign': 'center', 'minWidth': '80px', 'maxWidth': '100px', 'width': '90px'},
        style_data_conditional=style_data_conditional,
        page_size=20,
        export_format='csv',
        export_headers='display',
    )

# ÏΩúÎ∞± 6: [ÏÉÅÌò∏ÏûëÏö©] 'ÏÑ±Îä• Î≥ÄÌôîÏú®' ÌÉ≠Ïùò Í∑∏Î£π Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏Ïóê Îî∞Îùº Í∑∏ÎûòÌîÑÎ•º ÏóÖÎç∞Ïù¥Ìä∏
@app.callback(Output({'type': 'graph-container', 'index': MATCH}, 'children'), Input({'type': 'group-checklist', 'index': MATCH}, 'value'), State({'type': 'comparison-store', 'index': MATCH}, 'data'))
def update_graphs(selected_groups, json_data):
    if not selected_groups or not json_data: return []
    df = pd.read_json(json_data, orient='split')
    # change_df: columns=['Subgroup', 'L2_cache_miss_rate', 'ipc', ...]
    figures = []
    for stat in [col for col in df.columns if col != 'Subgroup']:
        fig = px.bar(df, x='Subgroup', y=stat, title=f"{stat} Change (%)", 
                     labels={stat: 'Change (%)', 'Subgroup': 'Subgroup'},
                     color_discrete_sequence=[PLOTLY_COLORS[i % len(PLOTLY_COLORS)]])
        fig.update_layout(title_x=0.5,
                         plot_bgcolor=COLORS['white'],
                         paper_bgcolor=COLORS['white'],
                         font={'color': COLORS['dark']})
        figures.append(dbc.Col(dcc.Graph(figure=fig), width=12, lg=6, xl=4))
    return dbc.Row(figures)

# ÏΩúÎ∞± 7: [ÏÉÅÌò∏ÏûëÏö©] 'HTMLÎ°ú Ï†ÄÏû•' Î≤ÑÌäº ÌÅ¥Î¶≠ Ïãú ÌååÏùº Îã§Ïö¥Î°úÎìú Ïã§Ìñâ
@app.callback(Output({'type': 'download-html', 'index': MATCH}, "data"), Input({'type': 'download-button', 'index': MATCH}, "n_clicks"), State({'type': 'comparison-store', 'index': MATCH}, "data"), State({'type': 'group-checklist', 'index': MATCH}, 'value'), State({'type': 'download-filename', 'index': MATCH}, 'value'), prevent_initial_call=True)
def download_html(n_clicks, json_data, selected_groups, filename):
    if not json_data or not selected_groups: return dash.no_update
    df = pd.read_json(json_data, orient='split')
    dff = df.loc[selected_groups].fillna(0).round(2).reset_index()
    html_string = dff.to_html(index=False, classes='table table-striped text-center', justify='center')
    final_filename = filename if filename else "report.html"
    if not final_filename.lower().endswith('.html'):
        final_filename += '.html'
    return dict(content=html_string, filename=final_filename)

# ÏΩúÎ∞± 8: [ÏÉÅÌò∏ÏûëÏö©] 'Ï†àÎåÄÍ∞í Î∂ÑÏÑù' ÌÉ≠Ïùò Í∑∏Î£π Ï≤¥ÌÅ¨Î¶¨Ïä§Ìä∏Ïóê Îî∞Îùº Í∑∏ÎûòÌîÑÎ•º ÏóÖÎç∞Ïù¥Ìä∏
@app.callback(
    Output({'type': 'abs-graph-container', 'index': MATCH}, 'children'),
    Input({'type': 'abs-group-checklist', 'index': MATCH}, 'value'),
    State({'type': 'abs-summary-store', 'index': MATCH}, 'data'),
    prevent_initial_call=True,
)
def update_absolute_graphs(selected_groups, json_data):
    if not selected_groups or not json_data:
        return []
    df = pd.read_json(json_data, orient='split')
    # group, statÎ≥ÑÎ°ú Í∑∏ÎûòÌîÑ ÏÉùÏÑ±
    figures = []
    for group in selected_groups:
        group_df = df[df['Group'] == group]
        for stat in group_df['Stat'].unique():
            stat_df = group_df[group_df['Stat'] == stat]
            fig = px.bar(stat_df, x='Subgroup', y='Value', title=f"{group} - {stat}", 
                         labels={'Value': stat, 'Subgroup': 'Subgroup'},
                         color_discrete_sequence=[PLOTLY_COLORS[i % len(PLOTLY_COLORS)]])
            fig.update_layout(title_x=0.5,
                             plot_bgcolor=COLORS['white'],
                             paper_bgcolor=COLORS['white'],
                             font={'color': COLORS['dark']})
            figures.append(dbc.Col(dcc.Graph(figure=fig), width=12, lg=6, xl=4))
    return dbc.Row(figures)

# Î∂ÑÏÑù ÏãúÏûë info ÏΩúÎ∞±
@app.callback(
    Output('analysis-info-start', 'children'),
    Input('run-button', 'n_clicks'),
    [State('baseline-dropdown', 'value'),
     State('target-checklist', 'value'),
     State('manual-path-input', 'value'),
     State('job-start-time-store', 'data')],
    prevent_initial_call=True,
)
def show_analysis_start_info(n_clicks, baseline_dir, target_dirs_checked, manual_paths, start_time):
    import datetime
    dirs = [baseline_dir] if baseline_dir else []
    if target_dirs_checked:
        dirs += list(target_dirs_checked)
    if manual_paths:
        dirs += [p.strip() for p in manual_paths.split('\n') if p.strip()]
    dirs = list(dict.fromkeys(dirs))
    if start_time:
        start_str = datetime.datetime.fromtimestamp(start_time).strftime('%Y-%m-%d %H:%M:%S')
    else:
        start_str = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    return [
        html.P(f"Target Directories: {', '.join(dirs) if dirs else 'None'}"),
        html.P(f"Analysis Start Time: {start_str}"),
        html.P("üîÑ Analysis in progress...", style={"color": COLORS['secondary'], "fontWeight": "600", "fontStyle": "italic"})
    ]

# Î∂ÑÏÑù ÏôÑÎ£å info ÏΩúÎ∞±
@app.callback(
    Output('analysis-info-complete', 'children'),
    Input('analysis-complete-store', 'data'),
    State('job-start-time-store', 'data'),
    prevent_initial_call=True,
)
def show_analysis_complete_info(analysis_complete, start_time):
    if not analysis_complete:
        return ""
    import time
    elapsed = None
    if start_time:
        elapsed = time.time() - start_time
    msg = [html.P("‚úÖ Analysis completed!", style={"color": COLORS['success'], "fontWeight": "bold", "fontSize": "1.1em"})]
    if elapsed is not None:
        mins, secs = divmod(int(elapsed), 60)
        msg.append(html.P(f"‚è±Ô∏è Elapsed Time: {mins} min {secs} sec", style={"color": COLORS['info'], "fontWeight": "500"}))
    # Ï∫êÏãú Ï†ïÎ≥¥ Ï∂îÍ∞Ä
    cache_info = get_cache_info()
    if 'error' not in cache_info:
        msg.append(html.P(f"üíæ Cache: {cache_info['cache_size']} files, "
                          f"{cache_info['hit_rate']:.1f}% hit rate",
                          style={"color": COLORS['secondary'], "fontSize": "0.9em"}))
    return msg

# ÎèÑÏõÄÎßê Î™®Îã¨ Ï†úÏñ¥ ÏΩúÎ∞±
@app.callback(
    Output("help-modal", "is_open"),
    [Input("help-button", "n_clicks"),
     Input("close-help", "n_clicks")],
    [State("help-modal", "is_open")],
    prevent_initial_call=True,
)
def toggle_help_modal(n1, n2, is_open):
    if n1 or n2:
        return not is_open
    return is_open

# HTML Ï†ÄÏû• ÏΩúÎ∞± (JS Í∏∞Î∞ò ÏïàÎÇ¥)
@app.callback(
    Output("save-status", "children"),
    Input("save-html-btn", "n_clicks"),
    prevent_initial_call=True,
)
def save_dashboard_html(n_clicks):
    if not n_clicks:
        return ""
    return html.Span(
        "Dashboard snapshot saved as HTML (see toast notification at bottom right). Filename: dashboard_snapshot_YYYYMMDD_HHMMSS.html",
        style={"color": COLORS['info'], "fontWeight": "500"}
    )

# ÏÇ¨Ïù¥ÎìúÎ∞î Ï†ëÌûò/ÌéºÏπ® Ï†úÏñ¥ ÏΩúÎ∞±
@app.callback(
    [Output("sidebar-content", "is_open"),
     Output("sidebar-header", "is_open"),
     Output("sidebar-toggle", "children"),
     Output("sidebar-col", "width")],
    Input("sidebar-toggle", "n_clicks"),
    [State("sidebar-content", "is_open")],
    prevent_initial_call=True,
)
def toggle_sidebar(n_clicks, is_open):
    if n_clicks:
        if is_open:
            # ÏÇ¨Ïù¥ÎìúÎ∞î Ï†ëÍ∏∞
            return False, False, "‚ñ∂", 1
        else:
            # ÏÇ¨Ïù¥ÎìúÎ∞î ÌéºÏπòÍ∏∞
            return True, True, "‚óÄ", 3
    return is_open, True, "‚óÄ", 3

# --- study_out_dir Î≥ÄÍ≤Ω Ïãú ÌïòÏúÑ ÎîîÎ†âÌÜ†Î¶¨ ÎèôÏ†Å ÏóÖÎç∞Ïù¥Ìä∏ ÏΩúÎ∞± ---
@app.callback(
    [Output('baseline-dropdown', 'options'),
     Output('target-checklist', 'options'),
     Output('study-out-dir-status', 'children'),
     Output('study-out-dir-store', 'data')],
    Input('study-out-dir-search-btn', 'n_clicks'),
    State('study-out-dir-input', 'value'),
    prevent_initial_call=True,
)
def update_dir_options(n_clicks, study_out_dir):
    import os
    if not study_out_dir or not os.path.isdir(study_out_dir):
        return [], [], f"‚ùå Directory not found: {study_out_dir}", dash.no_update
    discovered_dirs = find_subdirectories(Path(study_out_dir), depth=2)
    dir_options = [{'label': os.path.basename(p), 'value': p} for p in discovered_dirs]
    return dir_options, dir_options, f"‚úÖ Directory loaded: {study_out_dir}", study_out_dir

# Ï∫êÏãú ÏÉÅÌÉú ÌôïÏù∏ Ìï®Ïàò
def get_cache_info():
    """
    Ï∫êÏãú ÏÉÅÌÉú Ï†ïÎ≥¥Î•º Î∞òÌôò
    """
    try:
        cache_stats = cache.stats()
        cache_size = len(cache)
        cache_volume = cache.volume()
        
        # statsÍ∞Ä tupleÏù∏ Í≤ΩÏö∞ Ï≤òÎ¶¨
        if isinstance(cache_stats, dict):
            hits = cache_stats.get('hits', 0)
            misses = cache_stats.get('misses', 0)
        else:
            # statsÍ∞Ä tupleÏù∏ Í≤ΩÏö∞ (hits, misses)
            hits, misses = cache_stats if len(cache_stats) >= 2 else (0, 0)
        
        hit_rate = hits / max(hits + misses, 1) * 100
        
        return {
            'cache_hits': hits,
            'cache_misses': misses,
            'cache_size': cache_size,
            'cache_volume': cache_volume,
            'cache_directory': cache_directory,
            'hit_rate': hit_rate
        }
    except Exception as e:
        return {'error': str(e)}


if __name__ == "__main__":
    app.run(debug=False)
